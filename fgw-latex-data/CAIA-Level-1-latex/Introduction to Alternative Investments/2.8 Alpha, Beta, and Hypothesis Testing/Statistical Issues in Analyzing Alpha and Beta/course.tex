\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[version=4]{mhchem}
\usepackage{stmaryrd}

\begin{document}
\section*{Reading}
Statistical Issues in Analyzing Alpha and Beta

Two of the most central tasks in alternative investments are estimating alpha and beta in the sense that alpha and beta represent return and risk. This section applies the concepts of hypothesis testing and other statistical issues from previous sections of this session to the estimation of alpha and beta. Alternative investment is a field that emphasizes emerging asset groups, and therefore its empirical analysis must be on the cutting edge of investment research. But with that pioneering task comes the need to use exceptionally solid methods, as the body of knowledge is less established.

\section*{Non-Normality and the Cross-Sectional Search for Alpha}
Cross-sectional searches for alpha are especially prone to error when performance is analyzed with methods that assume normally distributed returns.

Suppose that an analyst is studying the return performance of 40 hedge fund managers. Assuming that all 40 funds have highly similar systematic risk exposures, the analyst uses a one-way statistical test assuming normality to determine which, if any, funds had a mean return that was 1.96 standard deviations or more above the average returns of the sample (a 97.5\% confidence interval). If a fund's return exceeded the test's threshold, the analyst judged the fund as having generated superior returns.

A well-trained analyst would note that one out of 40 funds would typically exceed the 1.96 standard deviation threshold simply by randomness. But suppose that the analyst observes that eight of the 40 fund managers achieved statistically superior returns by this criterion. Should the analyst conclude that such a high number of funds with superior performance must be attributable to the superior skill of most or all of those eight managers?

The logic of this analysis is appealing. If the null hypothesis is true (that returns are normally distributed and that all managers possess equal skill), it would be expected on average that only one fund manager in 40 would achieve statistically significant superior returns using a $97.5 \%$ confidence interval. It would seem that eight managers in 40 having statistically significant superior performance would be indicative of a cluster of skill.

A potential explanation of the finding is simply that the returns are not normally distributed. ${ }^{1}$ For example, assume that each of the 40 managers has the same level of skill. Each manager follows a strategy of making very short-term investment bets until one of two events happens: Either the fund rises $4 \%$ or it falls $1 \%$. All managers stop investing once they have hit either the $4 \%$ profit level or the $1 \%$ loss level. Assuming zero average returns for simplicity, there is an $80 \%$ probability that a manager will lose $1 \%$ and a $20 \%$ probability that a manager will earn $4 \%$. These are the only probabilities that sum to 1 and generate a zero expected return. Thus, on average, we could expect that eight of the managers would perform very well ( $+4 \%$ ) and 32 of the managers would lose a little ( $-1 \%)$. The standard deviation of the returns would be approximately $2 \%$, using the formula for standard deviation and the true probabilities of the outcomes. To exceed a $97.5 \%$ confidence interval, a manager would need to outperform the mean by 1.96 standard deviations or more, found with a cumulative normal distribution table. Each of the managers who earn $4 \%$ will outperform the mean by 2 standard deviations and therefore will have generated statistically significant superior returns. Crosssectional return differentials exist, but dispersion alone does not mean that skill is involved. In fact, the existence of any thickness or length to the tails of a frequency distribution of fund returns provides little or no evidence that the dispersion is caused by skill rather than luck.

\section*{Outliers and the Search for Alpha}
Another area of concern is whether empirical findings are being driven by one or more outliers. An outlier is an observation that is markedly further from the mean than almost all other observations. Outliers tend to have large impacts on results, and an exceptionally unusual outlier may severely distort the measurement of the economic tendencies of the data in traditional tests, especially in the case of small samples. Many statistical methodologies use squared values. When an outlier value is squared, its impact on the analysis can be huge. However, outliers also represent behavior that can be reasonably expected to recur, and therefore their inclusion in a sample may be useful in generating results that predict behavior well. Outliers often result from non-normally distributed variables, and they are often detected through visual inspection of plots or listings of observations ranked by the size of the regression residuals.

Visually examining plots of variables used in a statistical test can provide insight regarding their distribution, as well as the extent to which outliers may be driving the results. If past results are attributable to an outlier, an analysis based on those results may provide a poor indication of the future unless it is clear that the outlier is as likely to occur in the future as it was likely to occur in the past.

\section*{Biased Testing and the Search for Alpha}
Two issues of biased testing are: (1) Was the fund being analyzed selected at random, or was the fund identified prior to the sample period being analyzed? (2) Were the test procedures (such as the number of tests and the confidence levels) fully specified prior to the analysis of any results?

The first issue speaks to the tendency to observe a fund that has performed well and then to test if the performance is statistically superior. Did the person performing the test identify this fund based on noticing that it had performed well, or did a salesperson or financial publication bring this fund to the analyst's attention? If so, this test would be tantamount to standing outside a casino, observing a person who has won a great deal of money, and then testing to see if that person's winnings were statistically high.

The second issue speaks to the specification of the test and the importance of avoiding data dredging. Each statistical test typically involves numerous decisions, such as (1) the specification of the return model and benchmark or peer group, (2) the specification of the sample period, and (3) the specification of the significance level. It is vital that these decisions are made prior to the conduct of the test to avoid varying the specifications in search of a more favorable result.

\section*{Spurious Correlation, Causality, and Beta Estimation}
Beta estimation is a crucial task in measuring systematic risk for use in risk adjustment of returns. As a measure of correlation rather than a measure of central tendency, beta is inherently more difficult to analyze and more subject to complexities. Further, estimates of betas and correlations based on historical data can be highly unreliable. This section overviews the major challenges of estimating beta.

Virtually all of the challenges discussed in the previous sections regarding alpha estimation apply to the estimation of beta: non-normality of the underlying data, outliers, and biased testing. The primary additional challenges with estimation of beta discussed in this section are (1) differentiating between spurious correlation and true correlation, and (2) differentiating between true correlation and causality.

The difference between spurious correlation and true correlation is that spurious correlation is idiosyncratic in nature, coincidental, and limited to a specific set of observations. Estimates of security betas, even using a single-factor market model, are remarkably unstable over different time periods. Thus, the beta of an individual stock, a sophisticated hedge fund strategy, or an alternative investment such as a commodity tends to vary enormously based on the time period being analyzed. The estimated beta of individual stocks is regarded as so erratic that published estimates of beta are automatically adjusted for their historical tendencies toward 1.0 when used to predict future betas. Thus, if XYZ Corporation's beta over the past 60 months is estimated to be 2.0, a forecast of its future beta is often adjusted toward 1.0 (to a value of perhaps a little over 1.5) to provide a more realistic prediction of future correlation. This does not mean that there is no true correlation between XYZ and the market; it means that the correlation is changing or is difficult to measure, so estimates of beta are erratic over different time periods. The estimated correlation is being driven both by true correlation and by spurious correlation.

The difference between true correlation and causality is that causality reflects when one variable's correlation with another variable is determined by or due to the value or change in value of the other variable. Clearly, when the overall economy performs very well, it causes the net asset value of a long-only equity fund to rise.

The net asset value of one long-only equity fund might be highly correlated with another long-only equity fund, but there is no reason to believe that one fund's net asset value causes the other fund's net asset value to rise; they are rising together due to common underlying factors.

When economic reasoning indicates a causal relationship between two variables, an analyst or a researcher can be more confident that an observed correlation is true rather than spurious.

\section*{Fallacies of Alpha and Beta Estimation}
Alpha estimation is central to detecting potentially enhanced returns, while beta estimation is central to measuring the nondiversifiable risks of investments. This section discusses three common misunderstandings about alpha estimation and two common misunderstandings regarding beta estimation. To the extent that analysts are ignoring these issues, their conclusions are likely to be unsupported.

Three Fallacies of Alpha Estimation: Suppose that an analyst is studying a group of funds to identify possible investment opportunities that offer consistent superior risk-adjusted returns (ex ante alpha).

Fallacy 1 . If all funds being analyzed can reasonably be assumed to have highly similar systematic risk exposures, then if the analyst identifies numerous funds with statistically better performance (e.g., 12 managers out of 100 in a test with a $5 \%$ level of significance), the analyst should infer that some of the superior performance is attributable to managerial skill.

This conclusion is inaccurate. The results can be explained, and probably are explained, by the distribution of the unexplained returns being non-normal. The managers could all be skilled, all be unskilled, or be any combination in between. In fact, even if every fund manager studied had superior skill and there was absolutely no luck involved, if the skill differentials were normally distributed, only $5 \%$ of the managers on average would have statistically higher-than-average returns within the sample. The lesson is this: Returns should be analyzed using a risk-adjusted standard, such as a benchmark or an asset pricing model of efficiently priced assets, rather than compared to each other, and the results should be visually examined.

Fallacy 2. If the analyst examines an investment and estimates ex post alpha as the intercept of a time-series regression of the investment's returns using a multifactor asset pricing model, then a statistically positive alpha indicates that the investment earned a higher-than-average risk-adjusted return.

This conclusion is inaccurate. The test is a joint hypothesis of the appropriateness of the particular model of returns and of whether a particular fund has ex ante alpha. The observed result can be explained by model misspecification. It is very possible that the omission of a type of a systematic risk factor will cause the estimate of idiosyncratic performance, or alpha, to contain returns from bearing systematic risk. Thus, some of the funds being analyzed may have simply speculated on a risk that this model ignores, and happened to benefit from that risk with higher returns. The lesson is this: A hypothesis test is usually based on critical assumptions, so a test using a particular asset pricing model is only as reliable as the model itself.

Fallacy 3. Assuming that the asset pricing model is well specified, meaning it correctly captures and models all important systematic risks, if a statistically significant positive alpha is estimated using a significance level of $1 \%$, we can conclude that there is a $99 \%$ chance that the investment had a positive ex ante alpha, which denotes managerial skill.

This conclusion is inaccurate. As detailed in this session, the level of significance used in a hypothesis test is not the probability that the null hypothesis is false if a statistically significant result is found. The proper conclusion is that with a well-specified model, a fund that has zero ex ante alpha has only a $1 \%$ chance of being incorrectly estimated as having a nonzero ex ante alpha.

Two Fallacies of Beta Estimation: Beta estimation fallacies include the third fallacy of alpha estimation: that a statistically significant result with a significance level of $10 \%$ indicates that the null hypothesis has a $90 \%$ chance of being false. This section lists two additional common fallacies.

Fallacy 1. If an analyst performs a test of the relationship between a particular return series and a potential return factor, a consistent result that the coefficient is statistically equal to zero means that the investment's return was not related to that return factor, according to the observed data.

This conclusion is inaccurate. Traditional correlation measures indicate a linear response between the variables but may not capture some nonlinear relationships, such as U-shaped or V-shaped relationships. For example, the correlation between the returns of an at-the-money option straddle and the returns of the underlying assets may be zero, since the $\mathrm{V}$-shaped relationship generates positive returns for large increases or decreases in the underlying asset. The lesson is that alternative assets tend to contain nonlinear risk exposures and that complex statistical techniques suited to studying nonlinear relationships may need to be employed.

Fallacy 2. A statistically significant nonzero beta in a well-specified model indicates that the return factor causes at least part of the investment's return. This conclusion is inaccurate. Correlation can be different from causation. The price levels of most goods measured over the past century tend to be highly correlated because of inflation in the currency used to measure the prices. Thus, the long-term price level of gold might be highly correlated with the price level of a haircut, but neither of the prices causes the other price. The lesson is that economic intuition should play a role alongside empirical techniques to avoid misinterpretation of spurious correlation and to lessen the possibility of data dredging.

To conclude this session, recall the Trick Fund example, which introduced the lesson Using Statistical Methods to Locate Alpha. Can it be determined whether the Trick Fund offers ex ante alpha on the basis of empirical analysis alone? The answer is probably not. The reported returns for Bernard L. Madoff Investment Securities LLC generated an incredibly definitive empirical proof of ex ante alpha. However, the reported investment performance turned out to have been fictitious and fraudulent. Generally, high-quality alternative investment analysis requires economic reasoning as well as statistical and quantitative analysis.


\end{document}